{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 00:57:35.198127: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-31 00:57:35.365295: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-31 00:57:35.399135: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-31 00:57:36.724259: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/h/diya.li/usr/talib/lib:/h/diya.li/usr/talib/lib\n",
      "2022-10-31 00:57:36.724556: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/h/diya.li/usr/talib/lib:/h/diya.li/usr/talib/lib\n",
      "2022-10-31 00:57:36.724565: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "在使用天勤量化之前，默认您已经知晓并同意以下免责条款，如果不同意请立即停止使用：https://www.shinnytech.com/blog/disclaimer/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Model trainer\n",
      "dataloader: Loaded offline data from  2020-09-30 17:09:15 with 1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 00:57:56,462\tINFO worker.py:1518 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datetime import datetime\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import modin.pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "from pytorch_forecasting.data.examples import get_stallion_data\n",
    "\n",
    "# fix bug pytorch/30966\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
    "\n",
    "from models.model_trainer import ModelTrainer\n",
    "import pytz\n",
    "\n",
    "MT = ModelTrainer()\n",
    "data = MT.get_training_data()\n",
    "\n",
    "def _datetime_to_timestamp_nano(dt: datetime) -> int:\n",
    "    # timestamp() 返回值精度为 microsecond，直接乘以 1e9 可能有精度问题\n",
    "    return int(dt.timestamp() * 1000000) * 1000\n",
    "\n",
    "def _str_to_timestamp_nano(current_datetime: str, fmt=\"%Y-%m-%d %H:%M:%S.%f\") -> int:\n",
    "    return _datetime_to_timestamp_nano(datetime.strptime(current_datetime, fmt))\n",
    "\n",
    "def _to_ns_timestamp(input_time):\n",
    "    if type(input_time) in {int, float, np.float64, np.float32, np.int64, np.int32}:  # 时间戳\n",
    "        if input_time > 2 ** 32:  # 纳秒( 将 > 2*32数值归为纳秒级)\n",
    "            return int(input_time)\n",
    "        else:  # 秒\n",
    "            return int(input_time * 1e9)\n",
    "    elif isinstance(input_time, str):  # str 类型时间\n",
    "        return _str_to_timestamp_nano(input_time)\n",
    "    elif isinstance(input_time, datetime):  # datetime 类型时间\n",
    "        return _datetime_to_timestamp_nano(input_time)\n",
    "    else:\n",
    "        raise TypeError(\"暂不支持此类型的转换\")\n",
    "\n",
    "def time_to_s_timestamp(input_time):\n",
    "    return int(_to_ns_timestamp(input_time) / 1e9)\n",
    "\n",
    "def pre_process(data: pd.DataFrame):\n",
    "    data = pd.DataFrame(data)\n",
    "    exchange_tz = pytz.timezone('Asia/Shanghai')\n",
    "    data[\"datetime\"] =  data[\"datetime\"].apply(lambda x: datetime.utcfromtimestamp(x.value / 1e9).astimezone(exchange_tz))\n",
    "    data[\"time_idx\"] = data.index.values\n",
    "    data[\"is_daytime\"] = data[\"datetime\"].apply(lambda x: \"1\" if (x.hour >= 8 and x.hour < 16) else \"0\")\n",
    "    return data._to_pandas()\n",
    "\n",
    "def build_dataloader(data: pd.DataFrame):\n",
    "    max_prediction_length = 10\n",
    "    max_encoder_length = 30\n",
    "    training_cutoff = data[\"time_idx\"].iloc[-1] - max_prediction_length\n",
    "    variable_groups = {\n",
    "        \"time_variable\": [\"is_daytime\"],\n",
    "    }\n",
    "\n",
    "    training = TimeSeriesDataSet(\n",
    "        data[lambda x: x[\"time_idx\"] <= training_cutoff],\n",
    "        time_idx=\"time_idx\",\n",
    "        target=\"close\",\n",
    "        group_ids=[\"instrument_id\"],\n",
    "        weight=None,\n",
    "        min_encoder_length=max_encoder_length // 2,  # keep encoder length long (as it is in the validation set)\n",
    "        max_encoder_length=max_encoder_length,\n",
    "        min_prediction_length=1,\n",
    "        max_prediction_length=max_prediction_length,\n",
    "        static_categoricals=[\"instrument_id\"],\n",
    "        static_reals=[\"duration\"],\n",
    "        time_varying_known_categoricals=[\"time_variable\", \"underlying_symbol\"],\n",
    "        # variable_groups=variable_groups, \n",
    "        # time_varying_known_reals=[\"time_idx\"],\n",
    "        # time_varying_unknown_categoricals=[],\n",
    "        time_varying_unknown_reals=[\n",
    "            \"open\",\n",
    "            \"high\",\n",
    "            \"low\",\n",
    "            \"close\",\n",
    "            \"volume\",\n",
    "            \"open_oi\",\n",
    "            \"close_oi\",\n",
    "        ],\n",
    "        # target_normalizer=GroupNormalizer(groups=[\"instrument_id\", \"duration\"], transformation=\"softplus\"),  # use softplus and normalize by group\n",
    "        add_relative_time_idx=True,\n",
    "        add_target_scales=True,\n",
    "        add_encoder_length=True,\n",
    "        allow_missing_timesteps=True,\n",
    "    )\n",
    "\n",
    "    # create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "    # for each series\n",
    "    validation = TimeSeriesDataSet.from_dataset(training, data, predict=True, stop_randomization=True)\n",
    "    return training, validation\n",
    "data = pre_process(data)\n",
    "training, validation = build_dataloader(data)\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "actuals = torch.cat([y for x, (y, weight) in iter(val_dataloader)])\n",
    "baseline_predictions = Baseline().predict(val_dataloader)\n",
    "(actuals - baseline_predictions).abs().mean().item()\n",
    "\n",
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    gpus=0,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")\n",
    "\n",
    "\n",
    "# find optimal learning rate\n",
    "res = trainer.tuner.lr_find(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=20, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    gpus=1,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=30,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    output_size=7,  # 7 quantiles by default\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: lightning_logs/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0     \n",
      "1  | logging_metrics                    | ModuleList                      | 0     \n",
      "2  | input_embeddings                   | MultiEmbedding                  | 4     \n",
      "3  | prescalers                         | ModuleDict                      | 192   \n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 2.4 K \n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 5.5 K \n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 756   \n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "20 | output_layer                       | Linear                          | 119   \n",
      "----------------------------------------------------------------------------------------\n",
      "23.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.0 K    Total params\n",
      "0.092     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 31/31 [00:08<00:00,  3.56it/s, loss=1.1, v_num=0, train_loss_step=1.110, val_loss=0.765, train_loss_epoch=1.120] \n"
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=200,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 256),\n",
    "    hidden_continuous_size_range=(8, 256),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(\n",
    "        accelerator=\"cpu\",\n",
    "        devices=-1, \n",
    "        auto_select_gpus=True,\n",
    "        limit_train_batches=30\n",
    "        ),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte mean absolute error on validation set\n",
    "actuals = torch.cat([y[0] for x, y in iter(val_dataloader)])\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "(actuals - predictions).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions, x = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcualte metric by which to display\n",
    "predictions = best_tft.predict(val_dataloader)\n",
    "mean_losses = SMAPE(reduction=\"none\")(predictions, actuals).mean(1)\n",
    "indices = mean_losses.argsort(descending=True)  # sort losses\n",
    "for idx in range(10):  # plot 10 examples\n",
    "    best_tft.plot_prediction(\n",
    "        x, raw_predictions, idx=indices[idx], add_loss_to_title=SMAPE(quantiles=best_tft.loss.quantiles)\n",
    "    );\n",
    "# plot worst 10 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, x = best_tft.predict(val_dataloader, return_x=True)\n",
    "predictions_vs_actuals = best_tft.calculate_prediction_actual_by_variable(x, predictions)\n",
    "best_tft.plot_prediction_actual_by_variable(predictions_vs_actuals);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('quant')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0abbc273188c894ba1b5dc907fa703b1a9ac85344fd54c43c2942a4b4a92e6fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
